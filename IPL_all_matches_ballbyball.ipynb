{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import yaml\n",
    "import os\n",
    "os.chdir('C:\\\\Users\\\\401738\\\\Downloads\\\\ipl\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNCTION to load each YAML files for a particular IPL season. #start and #end variables are the starting and ending file names "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(start , end ):\n",
    "    matches = []\n",
    "    for i in range(start, end):\n",
    "        if os.path.isfile('./'+str(i)+'.yaml'):\n",
    "            with open('./'+str(i)+'.yaml','r')as f:\n",
    "                doc= yaml.load(f)\n",
    "                matches.append(doc)\n",
    "    return matches\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the above function and passing the start and end file names to load the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2008 = load_data(335982,336041)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2009 = load_data(392181,392240 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2010 = load_data(419106,419166)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2011 = load_data(501198, 501272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2012 = load_data(548306, 548382)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2013 = load_data(597998, 598074)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2014 = load_data(729279, 734050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2015 = load_data(829705, 829824)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2016 = load_data(980901, 981020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "m_2017 = load_data(1082591, 1082651)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function extracts important information from each match of a season,viz runs per over , wickets per over and total runs in each innings in the form of a DICTIONARY object. You need to only pass the innings dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_data(innings):\n",
    "    total_runs =0\n",
    "    k=0.0\n",
    "    prev=0.0\n",
    "    over_runs = {}\n",
    "    over_wickets = {}\n",
    "    runs= 0\n",
    "    w_counter = 0\n",
    "    for i in range(0,len(innings)):\n",
    "        #if (i==0):\n",
    "            #print ('Match Started: Over # 1')\n",
    "        for k , v in innings[i].items():\n",
    "            if ((prev//1) != (k//1)):\n",
    "                #print ('Over #', int((prev//1) +1),' completed')\n",
    "                #print ('Runs Scored #',runs)\n",
    "                runs+= int(innings[i][k]['runs']['total'])\n",
    "                if ('wicket' in innings[i][k]):\n",
    "                    w_counter+=1\n",
    "                    over_wickets[k] = [w_counter,innings[i][k]['wicket']['player_out'],innings[i][k]['wicket']['kind']]\n",
    "                    #print (' Over -', k,'Out!!','wicket #',w_counter, innings[i][k]['wicket']['player_out'],innings[i][k]['wicket']['kind'])\n",
    "                over_runs[int((prev//1) +1)]= int(runs)\n",
    "                #print ('Over #', int((k//1) +1),' started and running')\n",
    "                runs = 0\n",
    "            else:\n",
    "                #print ('Over #', int((prev//1) +1),' running')\n",
    "                runs+= int(innings[i][k]['runs']['total'])\n",
    "                if ('wicket' in innings[i][k]):\n",
    "                    w_counter+=1\n",
    "                    over_wickets[k] = [w_counter,innings[i][k]['wicket']['player_out'],innings[i][k]['wicket']['kind']]\n",
    "                    #rint (' Over -', k,'Out!!','wicket #',w_counter, innings[i][k]['wicket']['player_out'],innings[i][k]['wicket']['kind'])\n",
    "            prev = k\n",
    "            total_runs+= innings[i][k]['runs']['total']\n",
    "        if( i == len(innings) -1 ):\n",
    "            #print ('Over #', int((prev//1) +1),' completed')\n",
    "            #print ('Runs Scored #',runs)\n",
    "            over_runs[int((prev//1) +1)]= int(runs)\n",
    "    return over_runs , over_wickets , total_runs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function wraps the DICTIONARY objects created by the above function for a match and stores the same for all the matches in a season into a LIST object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_data(matches):\n",
    "    rpo_innings1 = []\n",
    "    rpo_innings2 = []\n",
    "    wpo_innings1 = []\n",
    "    wpo_innings2 = []\n",
    "    tr_innings1 = []\n",
    "    tr_innings2 = []\n",
    "    team_innings1 = []\n",
    "    team_innings2 = []\n",
    "    misc_info = []\n",
    "    \n",
    "    for i in range(0,len(matches)):\n",
    "        \n",
    "        if (len(matches[i]['innings']) > 1):\n",
    "            \n",
    "            rpo_i1 , wpo_i1 , tr_i1 = extract_data(matches[i]['innings'][0]['1st innings']['deliveries'])\n",
    "            rpo_innings1.append(rpo_i1)\n",
    "            wpo_innings1.append(wpo_i1)\n",
    "            tr_innings1.append(tr_i1)\n",
    "            team_innings1.append(matches[i]['innings'][0]['1st innings']['team'])\n",
    "        \n",
    "            rpo_i2 , wpo_i2 , tr_i2 = extract_data(matches[i]['innings'][1]['2nd innings']['deliveries'])\n",
    "            rpo_innings2.append(rpo_i2)\n",
    "            wpo_innings2.append(wpo_i2)\n",
    "            tr_innings2.append(tr_i2)\n",
    "            team_innings2.append(matches[i]['innings'][1]['2nd innings']['team'])\n",
    "           \n",
    "            \n",
    "            misc_info.append([matches[i]['info']['venue'],matches[i]['info']['toss']['winner'],matches[i]['info']['toss']['decision'],matches[i]['info']['outcome']])\n",
    "        else :\n",
    "            pass\n",
    "            \n",
    "    return rpo_innings1, rpo_innings2 , wpo_innings1 , wpo_innings2 , tr_innings1, tr_innings2, team_innings1 , team_innings2,misc_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calling the above function and creating a series of LIST objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rpo_i1_2008,rpo_i2_2008,wpo_i1_2008,wpo_i2_2008,tr_i1_2008,tr_i2_2008,team_i1_2008,team_i2_2008,misc_info_2008 = generate_data(m_2008)\n",
    "rpo_i1_2009,rpo_i2_2009,wpo_i1_2009,wpo_i2_2009,tr_i1_2009,tr_i2_2009,team_i1_2009,team_i2_2009,misc_info_2009 = generate_data(m_2009)\n",
    "rpo_i1_2010,rpo_i2_2010,wpo_i1_2010,wpo_i2_2010,tr_i1_2010,tr_i2_2010,team_i1_2010,team_i2_2010,misc_info_2010 = generate_data(m_2010)\n",
    "rpo_i1_2011,rpo_i2_2011,wpo_i1_2011,wpo_i2_2011,tr_i1_2011,tr_i2_2011,team_i1_2011,team_i2_2011,misc_info_2011 = generate_data(m_2011)\n",
    "rpo_i1_2012,rpo_i2_2012,wpo_i1_2012,wpo_i2_2012,tr_i1_2012,tr_i2_2012,team_i1_2012,team_i2_2012,misc_info_2012 = generate_data(m_2012)\n",
    "rpo_i1_2013,rpo_i2_2013,wpo_i1_2013,wpo_i2_2013,tr_i1_2013,tr_i2_2013,team_i1_2013,team_i2_2013,misc_info_2013 = generate_data(m_2013)\n",
    "rpo_i1_2014,rpo_i2_2014,wpo_i1_2014,wpo_i2_2014,tr_i1_2014,tr_i2_2014,team_i1_2014,team_i2_2014,misc_info_2014 = generate_data(m_2014)\n",
    "rpo_i1_2015,rpo_i2_2015,wpo_i1_2015,wpo_i2_2015,tr_i1_2015,tr_i2_2015,team_i1_2015,team_i2_2015,misc_info_2015 = generate_data(m_2015)\n",
    "rpo_i1_2016,rpo_i2_2016,wpo_i1_2016,wpo_i2_2016,tr_i1_2016,tr_i2_2016,team_i1_2016,team_i2_2016,misc_info_2016 = generate_data(m_2016)\n",
    "rpo_i1_2017,rpo_i2_2017,wpo_i1_2017,wpo_i2_2017,tr_i1_2017,tr_i2_2017,team_i1_2017,team_i2_2017,misc_info_2017 = generate_data(m_2017)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import linear_model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes wickets per over dictionary created earlier, and returns the total wickets that has fallen during a match for a particular team."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_wpo(wpo):  \n",
    "    wickets= []\n",
    "    for i in range(len(wpo)):\n",
    "        wickets.append([(int(k//1) + 1) for k, v in wpo[i].items()])\n",
    "    wickets_full=[]\n",
    "    for li in wickets:\n",
    "        wickets_full.append([0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0])\n",
    "        for i in li:\n",
    "            if i in range(1,21):\n",
    "                wickets_full[wickets.index(li)][i-1] += 1 \n",
    "    return wickets_full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function below creates a full Dataset combining all the above extracted information on an innings level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_full_dataset(rpo_inn, tr_inn , wpo_inn):\n",
    "    rpo_inn_df = pd.DataFrame.from_dict(rpo_inn)\n",
    "    tr_inn_df = pd.DataFrame(tr_inn, columns =['Total'])\n",
    "    w_inn_df = pd.DataFrame([len(i) for i in wpo_inn], columns = ['wickets'])\n",
    "    runs_wickets_inn_df = w_inn_df.join(tr_inn_df)\n",
    "\n",
    "    wickets_full = add_wpo(wpo_inn)\n",
    "    wickets_df = pd.DataFrame(wickets_full,columns=['wickts_1','wickts_2','wickts_3','wickts_4','wickts_5','wickts_6',\n",
    "                     'wickts_7','wickts_8','wickts_9','wickts_10','wickts_11','wickts_12','wickts_13','wickts_14',\n",
    "                     'wickts_15','wickts_16','wickts_17','wickts_18','wickts_19','wickts_20'])\n",
    "    inn_df = rpo_inn_df.join(wickets_df)\n",
    "    inn_df = inn_df.join(runs_wickets_inn_df)\n",
    "    inn_df.columns = ['runs_1','runs_2','runs_3','runs_4','runs_5','runs_6','runs_7','runs_8','runs_9','runs_10','runs_11','runs_12',\n",
    "                     'runs_13','runs_14','runs_15','runs_16','runs_17','runs_18','runs_19','runs_20','wickts_1','wickts_2',\n",
    "                     'wickts_3','wickts_4','wickts_5','wickts_6','wickts_7','wickts_8','wickts_9','wickts_10','wickts_11',\n",
    "                     'wickts_12','wickts_13','wickts_14','wickts_15','wickts_16','wickts_17','wickts_18','wickts_19','wickts_20',\n",
    "                     'wickets','Total']\n",
    "    return inn_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1_df = create_full_dataset(rpo_i2_2012, tr_i2_2012, wpo_i2_2012)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "misc_df = pd.DataFrame(misc_info_2008, columns =['venue','toss_winner','toss_decision','match_winner'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58 57 60 73 74 76 60 59 60 59\n"
     ]
    }
   ],
   "source": [
    "print (len(m_2008),len(m_2009),len(m_2010),len(m_2011),len(m_2012),len(m_2013),len(m_2014),len(m_2015),len(m_2016),len(m_2017))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = i1_df['Total'][0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_test = i1_df['Total'][41:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "i1_df=i1_df.drop(['runs_7','runs_8','runs_9','runs_10','runs_11','runs_12',\n",
    "                     'runs_13','runs_14','runs_15','runs_16','runs_17','runs_18','runs_19','runs_20','wickts_7','wickts_8','wickts_9','wickts_10','wickts_11',\n",
    "                     'wickts_12','wickts_13','wickts_14','wickts_15','wickts_16','wickts_17','wickts_18','wickts_19','wickts_20',\n",
    "                     'wickets','Total'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = i1_df[0:40]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = i1_df[41:74]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = x_train.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = x_test.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train= scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_test = scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5.,   10.,   14., ...,    0.,    4.,  144.],\n",
       "       [  12.,    9.,    7., ...,    0.,    6.,  163.],\n",
       "       [   6.,    7.,    6., ...,    0.,    6.,  119.],\n",
       "       ..., \n",
       "       [   7.,   17.,    7., ...,    1.,    9.,  149.],\n",
       "       [   7.,   10.,    5., ...,    0.,   10.,  136.],\n",
       "       [   3.,    7.,   10., ...,    0.,    5.,  192.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler.inverse_transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Continuum\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "C:\\Continuum\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\preprocessing\\data.py:586: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2 = StandardScaler()\n",
    "scaler2.fit(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Continuum\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "C:\\Continuum\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "y_train = scaler2.transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Continuum\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\utils\\validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n",
      "C:\\Continuum\\Anaconda2\\envs\\TFENV\\lib\\site-packages\\sklearn\\preprocessing\\data.py:649: DeprecationWarning: Passing 1d arrays as data is deprecated in 0.17 and will raise ValueError in 0.19. Reshape your data either using X.reshape(-1, 1) if your data has a single feature or X.reshape(1, -1) if it contains a single sample.\n",
      "  warnings.warn(DEPRECATION_MSG_1D, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "y_test = scaler2.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 144.,  163.,  119.,  150.,  143.,  134.,  174.,  185.,  154.,\n",
       "        126.,  145.,  142.,  127.,  138.,  155.,  115.,  125.,  194.,\n",
       "        173.,  160.,  140.,  108.,  123.,  194.,  128.,  145.,  102.,\n",
       "        123.,  163.,  144.,  149.,  136.,  192.])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2.inverse_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "reg = linear_model.Ridge(alpha= .9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "p = PCA(n_components = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PCA(copy=True, iterated_power='auto', n_components=2, random_state=None,\n",
       "  svd_solver='auto', tol=0.0, whiten=False)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.fit(x_train.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train_new = p.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=0.9, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_pred = reg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 141.29632681,  157.6016125 ,  120.78512697,  148.74103693,\n",
       "        139.11911903,  138.89741282,  171.23521683,  185.40427587,\n",
       "        159.12609394,  122.16799209,  145.13902621,  139.68902215,\n",
       "        130.22822947,  137.53364879,  156.65785718,  116.18106806,\n",
       "        121.87718932,  192.86061009,  166.38972559,  155.19740605,\n",
       "        135.16478717,  113.14151342,  123.11501252,  190.75254659,\n",
       "        130.33536351,  150.72617534,  104.80437467,  128.49835882,\n",
       "        165.33781178,  143.07718656,  142.45009346,  135.90851336,\n",
       "        193.81579109])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler2.inverse_transform(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97778247650942163"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
